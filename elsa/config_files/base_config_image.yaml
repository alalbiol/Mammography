General:
  source_root: /home/eblanov/proymam2/Mammography/mamo_holistic
  gpu_type: "RTX 3090" 

Datamodule:
  ddsm_root: /home/Data/mamo/DDSM_png_16bit_1120x896
  train_csv: resources/ddsm/ddsm_nikulin_partitions/train_filenames.txt
  val_csv: resources/ddsm/ddsm_nikulin_partitions/valid_filenames.txt        #CAMBIADO DE 1152 A 1120
  ddsm_annotations: resources/ddsm/ddsm_annotations_16bits_1120_896.json.gz
  convert_to_rgb: False
  return_mask: True
  #ddsm_root: /home/alalbiol/Data/mamo/DDSM_png_16bit_1152x896
  batch_size: 24
  balanced_patches: True
  num_workers: 32
  pin_memory: True
  dream_pilot_folder: /home/Data/mamo/dream_pilot_png_832x1152
  #subset_size_train: 1000
  #subset_size_test: 100


Logger:
  type: wandb
  project: ddsm_image
  name: nikulin_image_lr_1e-4_patch_448_mask_lession
  save_dir: /tmp/logs/nikulin_image_lr_1e-4_patch_448_mask_lession

LightningModule:
  model_name: nikulin
  model_params:
    patch_model_weights_path: /home/eblanov/proymam2/Mammography/mamo_holistic/checkpoints/best_model_nikulin_patch_448_epoch=172-step=22663-val_auroc=0.87.ckpt
    #patch_model_weights_path: /home/alalbiol/Programacion/Mammography/mamo_holistic/checkpoints/best_model_nikulin_patch_epoch=94-step=9690-val_auroc=0.87.ckpt
    #ckpt_path: /home/alalbiol/Programacion/mammography/others/nikulin/data/SC1_nets/Final_Round_RC1/best_model.ckpt-3750
    #ckpt_path: /home/alalbiol/Programacion/Mammography/mamo_holistic/Nikulin/package/SC1_nets/3rd_Round_RC1/best_model.ckpt-3500
  learning_rate: 0.0001
  optimizer_type: adam
  num_classes: 2
  loss_name: smoothed_cross_entropy
  loss_params:
    smoothing: 0.1
    num_classes: 2
  #lr_scheduler: ReduceLROnPlateau
  #lr_scheduler_options:
  #  mode: max
  #  factor: 0.5
  #  patience: 20
  #  min_lr: 1.e-8
  test_time_augmentation: True
  #mixup_alpha: 0.3


Trainer:
  max_epochs: 600
  log_every_n_steps: 3
  precision: 16-mixed
  #check_val_every_n_epoch: 10
  #limit_train_batches: 10



Callbacks:
  # EarlyStopping:
  #   monitor: val_loss
  #   mode: min
  #   patience: 60
  #   verbose: True
  VisualizeBatch:
    num_rows: 2
  LearningRateMonitor:
    logging_interval: 'epoch'
  FreezePatchLayersCallback:
    freeze_epochs: 5
  ModelCheckpoint:
    monitor: val_auroc
    mode: max
    save_top_k: 1
    dirpath: /tmp/logs/nikulin_image
    filename: best_model_nikulin_image-from-448_mask_lession-{step}-{val_auroc:.2f}
    verbose: True
  #EMACallback:
  #  decay: 0.9
  
  