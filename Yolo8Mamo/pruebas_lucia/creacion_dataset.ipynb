{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddsm_dir = pathlib.Path('/home/Data/mamo/DDSM_png')\n",
    "labels_dir = '/home/lloprib/proyecto_mam/Mammography/Yolo8Mamo/func_pruebas_lucia/labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def _init_(self, img_dir, labels_dir, nclass, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.nclass = nclass\n",
    "        self.img_labels = [f for f in os.listdir(labels_dir) if f.endswith('.txt') ] \n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        carpetas=self.img_labels[idx].split('.')\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, carpetas ,self.img_labels[idx].replace('.txt', '.jpg'))  # Assuming image files are .jpg\n",
    "        image = Image.open(img_path)\n",
    "        img_width, img_height = image.size\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Read the label from the corresponding text file\n",
    "        label_path = os.path.join(self.labels_dir, self.img_labels[idx])\n",
    "        objeto=[]\n",
    "        faster_rcnn_boxes = []\n",
    "        with open(label_path, 'r') as file:\n",
    "            label_data = file.readlines()\n",
    "            if label_data:\n",
    "                for line in label_data:\n",
    "                    objeto.append(1)\n",
    "                    coordenadas = list(map(float, line.strip().split()[1:]))\n",
    "                    coordenadas_yolo=[(max(coordenadas[::2])+min(coordenadas[::2]))/2, \n",
    "                                             (max(coordenadas[1::2])+min(coordenadas[1::2]))/2, \n",
    "                                             max(coordenadas[::2])-min(coordenadas[::2]),\n",
    "                                             max(coordenadas[1::2])-min(coordenadas[1::2])]\n",
    "\n",
    "                    x_center, y_center, width, height = coordenadas_yolo\n",
    "                    \n",
    "                    x_min = (x_center - width / 2) * img_width\n",
    "                    y_min = (y_center - height / 2) * img_height\n",
    "                    x_max = (x_center + width / 2) * img_width\n",
    "                    y_max = (y_center + height / 2) * img_height\n",
    "                    faster_rcnn_boxes.append([x_min, y_min, x_max, y_max])\n",
    "                target = {\n",
    "                'boxes': torch.tensor(faster_rcnn_boxes),  \n",
    "                'labels': torch.tensor(objeto)  \n",
    "                }\n",
    "            else:\n",
    "                 target = {\n",
    "                'boxes': torch.zeros((0, 4), dtype=torch.float32),\n",
    "                'labels': torch.zeros((0,), dtype=torch.int64)\n",
    "                 }\n",
    "        \n",
    "        if self.transform:\n",
    "                    # Apply the same transform to the bounding boxes\n",
    "                    for i in range(len(target['boxes'])):\n",
    "                        box = target['boxes'][i]\n",
    "                        x_min, y_min, x_max, y_max = box\n",
    "                        box = torch.tensor([\n",
    "                            x_min / img_width * 800,  # Escala X (xmin)\n",
    "                            y_min / img_height * 800, # Escala Y (ymin)\n",
    "                            x_max / img_width * 800,  # Escala X (xmax)\n",
    "                            y_max / img_height * 800  # Escala Y (ymax)\n",
    "                        ])\n",
    "                        target['boxes'][i] = box\n",
    "\n",
    "        return image, target\n",
    "\n",
    "transform = T.Compose([#PROBAR A REDIMENSIONAR A 800X800 PARA VER SI MEJORA\n",
    "    T.Resize(800),        # Redimensiona el lado más pequeño a 256, manteniendo el aspect ratio\n",
    "    T.CenterCrop((800, 800)),  # Recorta el centro a 256x256\n",
    "    T.ToTensor(), \n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "    # Update the dataset to use the new transform\n",
    "train_dataset = CustomImageDataset(img_dir=ddsm_dir, labels_dir=labels_dir, \n",
    "                                   nclass=1,transform=transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
