{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pathlib \n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader\n",
    "import torch.utils.data as data \n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os \n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "import matplotlib.patches as patches\n",
    "from clases_train_mamo import bounding_boxes_coord, CustomDataset, CustomModel\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models import ResNet50_Weights\n",
    "import lightning as L\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = pathlib.Path(\"/home/Data/CBIS-DDSM-segmentation-2240x1792/images\")\n",
    "bb = pathlib.Path(\"/home/Data/CBIS-DDSM-segmentation-2240x1792/bounding_boxes.csv\")\n",
    "\n",
    "normalize = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "total_dataset = CustomDataset(img_dir = image_directory, labels_file = bb, transform = normalize)\n",
    "\n",
    "# Dividir los elementos en dos conjuntos: 80% para entrenamiento y 20% para prueba\n",
    "print(\"Entrada a la division de los conjuntos\")\n",
    "\n",
    "# Calcular los tamaños de los conjuntos de entrenamiento y prueba\n",
    "train_size = int(0.8 * len(total_dataset))\n",
    "test_size = len(total_dataset) - train_size\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "train_dataset, test_dataset = random_split(total_dataset, [train_size, test_size])\n",
    "\n",
    "#train_dataset, test_dataset = train_test_split(total_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "valid_size = int(0.2 * train_size)\n",
    "train2_size = train_size - valid_size\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "_, valid_dataset = data.random_split(train_dataset, [train2_size, valid_size], generator = seed)\n",
    "device = 'cuda'\n",
    "\n",
    "print(\"Dataset generados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn= lambda x: tuple(zip(*x)))\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn= lambda x: tuple(zip(*x)))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn= lambda x: tuple(zip(*x)))\n",
    "\n",
    "print(\"Dataloader generados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasterrcnn_resnet50_fpn(num_classes=2, weights_backbone=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "Lmodel = CustomModel(model)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint( # Para que guarde las tres mejores épocas \n",
    "    monitor='val_map',\n",
    "    dirpath='/home/lloprib/',\n",
    "    filename='mamo-{epoch:02d}-{val_map:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=100, \n",
    "    devices='auto',\n",
    "    accelerator='gpu',\n",
    "    default_root_dir='/home/lloprib/proyecto_mam/Mammography/Yolo8Mamo/pruebas_lucia/checkpoints/',\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(Lmodel, train_dataloader, valid_dataloader)\n",
    "\n",
    "\n",
    "trainer.test(Lmodel, dataloaders = test_dataloader)\n",
    "\n",
    "\n",
    "print(\"Training finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
