General:
  source_root: /home/alalbiol/Programacion/Mammography/mamo_holistic
  gpu_type: "RTX 3090" 

Datamodule:
  patch_size: 224
  convert_to_RGB: True
  split_csv: resources/ddsm/DDSM_train.csv
  ddsm_annotations: resources/ddsm/ddsm_annotations.json.gz
  ddsm_root: /home/alalbiol/Data/mamo/DDSM_png_1152x896
  eval_patches_root: /home/alalbiol/Data/mamo/DDSM_eval_patches/eval_patches_224
  batch_size: 32
  num_workers: 16
  pin_memory: True


Logger:
  type: wandb
  project: ddsm_patch
  name: patches_224
  save_dir: /tmp/logs/ddsm_patch_224

LightningModule:
  learning_rate: 0.001
  optimizer_type: adam
  num_classes: 5
  #subset_train_size: 1000
  #subset_val_size: 100
  lr_scheduler: ReduceLROnPlateau
  lr_scheduler_options:
    mode: min
    factor: 0.1
    patience: 5
    min_lr: 1e-8

Trainer:
  max_epochs: 100


Callbacks:
  EarlyStopping:
    monitor: val_loss
    mode: min
    patience: 20
    verbose: True

  
  ModelCheckpoint:
    monitor: val_loss
    mode: min
    save_top_k: 1
    dirpath: /tmp/logs/ddsm_patch_224
    filename: best_model
    verbose: True
  
  